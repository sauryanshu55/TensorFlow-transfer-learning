# -*- coding: utf-8 -*-
"""04-transfer-learning-in-TensorFlow-1:feature-extraction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VM5jks0WbsSI32RZpds2nxPm_ngyeByM

## Transfer learning with TensorFlow, Part 1: Feature Extraction
"""

!nvidia-smi

"""# Becoming one with the data"""

import zipfile
!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip
zip_ref=zipfile.ZipFile('10_food_classes_10_percent.zip')
zip_ref.extractall()
zip_ref.close()

import os
for dirpath, dirnames, filenames in os.walk('10_food_classes_10_percent'):
    print(f'Number of Directories (Classes): {len(dirnames)} Number of images: {len(filenames)} in {dirpath}')

"""# Create Data loaders"""

# Setup data inputs
from tensorflow.keras.preprocessing.image import ImageDataGenerator

IMAGE_SHAPE=(224,224)
BATCH_SIZE=32

train_dir='10_food_classes_10_percent/train/'
test_dir='10_food_classes_10_percent/test/'

train_datagen=ImageDataGenerator(rescale=1/255.)
test_datagen=ImageDataGenerator(rescale=1/255.)

print('Training Images:')
train_data_10_percent=train_datagen.flow_from_directory(
    train_dir,
    target_size=IMAGE_SHAPE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
)

print('Testing Images:')
test_data=train_datagen.flow_from_directory(
    test_dir,
    target_size=IMAGE_SHAPE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
)

"""## Setting up callbacks"""

# Functionize and create TensorBoard callback
import tensorflow as tf
import datetime

def create_tensorboard_callback(dir_name, experiment_name,):
    log_dir=dir_name+'/'+experiment_name+'/'+datetime.datetime.now().strftime('%Y%m%d-%H%M%S')
    tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=log_dir)
    print(f'Saving TensorBoard logfiles to: {log_dir}....')
    return tensorboard_callback

"""# Creating models using TensorFlow Hub"""

# Comparing the two TF hub models
resnet_url='https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5'
efficientnet_url='https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1'

# Impoirt dependencies
import tensorflow as tf
import tensorflow_hub as hub
from tensorflow.keras import layers

# create_model() func to create model from TF hub URL
def create_model(model_url, num_classes=10):
  """
  Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.
  """
  # Download the pretrained model and save it as a Keras layer
  feature_extractor_layer = hub.KerasLayer(model_url,
                                           trainable=False, # freeze the already learned patterns
                                           name="feature_extraction_lyaer",
                                           input_shape=IMAGE_SHAPE+(3,)) 

  # Create our own model
  model = tf.keras.Sequential([
    feature_extractor_layer,
    layers.Dense(num_classes, activation="softmax", name="output_layer")
  ])
    
  return model

"""## Creating and testing ResNet TensorFlow Hub fearture extraction model"""

# Create Resnet Model
resnet_model=create_model(resnet_url,
                          num_classes=train_data_10_percent.num_classes)

resnet_model.summary()

from tensorflow.python import metrics
# Compile the ResNet model
resnet_model.compile(
    loss='categorical_crossentropy',
    optimizer=tf.keras.optimizers.Adam(),
    metrics=['accuracy'],
)

# Fit the ResNet model to the data
resnet_history=resnet_model.fit(train_data_10_percent,
                               epochs=5,
                               steps_per_epoch=len(train_data_10_percent),
                               validation_data=test_data,
                               validation_steps=len(test_data),
                               callbacks=[create_tensorboard_callback(dir_name='tensorflow_hub',
                                                                      experiment_name='resnet50V2')]
                               )

# Create function to plot loss curves

import matplotlib.pyplot as plt

# Plot validation and training ccurves
def plot_loss_curves(history):
    """Returns seperate loss curves for training and validation metrics"""

    loss=history.history['loss']
    val_loss=history.history['val_loss']

    accuracy=history.history['accuracy']
    val_accuracy=history.history['val_accuracy']

    epochs=range(len(history.history['loss']))

    # Plot loss
    plt.plot(epochs,loss,label='training_loss')
    plt.plot(epochs,val_loss,label='val_loss')
    plt.title('Loss')
    plt.xlabel('Epochs')
    plt.legend()

    # Plot accuracy
    plt.figure()
    plt.plot(epochs,accuracy,label='training_accuracy')
    plt.plot(epochs,val_accuracy, label='val_accuracy')
    plt.title('Accuracy')
    plt.xlabel('Epochs')
    plt.legend()

plot_loss_curves(resnet_history)

"""## Creating and testing EfficientNetB0 TensorFlow Hub Feature Extraction model"""

# Create EfficientNetB0 feature extractor model
efficientnet_model=create_model(model_url=efficientnet_url,
                                num_classes=train_data_10_percent.num_classes)

#Compile EfficientNet model
efficientnet_model.compile(
    loss='categorical_crossentropy',
    optimizer=tf.keras.optimizers.Adam(),
    metrics=['accuracy']
)

# Fit the model
efficientnet_history=efficientnet_model.fit(
    train_data_10_percent,
    epochs=5,
    steps_per_epoch=len(train_data_10_percent),
    validation_data=test_data,
    validation_steps=len(test_data),
    callbacks=[create_tensorboard_callback(dir_name='tensorflow_hub',
                                           experiment_name='efficientnetb0') ]
)